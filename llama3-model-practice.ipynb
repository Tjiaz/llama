{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":33551,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":28083}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-02T22:01:29.189668Z","iopub.execute_input":"2024-07-02T22:01:29.190302Z","iopub.status.idle":"2024-07-02T22:01:30.198267Z","shell.execute_reply.started":"2024-07-02T22:01:29.190269Z","shell.execute_reply":"2024-07-02T22:01:30.197358Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/llama-3/transformers/8b-chat-hf/1/model.safetensors.index.json\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00003-of-00004.safetensors\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/config.json\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/LICENSE\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00001-of-00004.safetensors\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/model.py\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/USE_POLICY.md\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/tokenizer.json\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/tokenizer_config.json\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/example_text_completion.py\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/test_tokenizer.py\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/requirements.txt\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/tokenizer.py\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00004-of-00004.safetensors\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/eval_details.md\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/special_tokens_map.json\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/generation.py\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00002-of-00004.safetensors\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/__init__.py\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/example_chat_completion.py\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/setup.py\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/generation_config.json\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n%pip install -U transformers \n%pip install -U datasets \n%pip install -U accelerate \n%pip install -U peft \n%pip install -U trl \n%pip install -U bitsandbytes \n%pip install -U wandb\n%pip install --upgrade pyarrow","metadata":{"execution":{"iopub.status.busy":"2024-07-02T22:07:18.791158Z","iopub.execute_input":"2024-07-02T22:07:18.791891Z","iopub.status.idle":"2024-07-02T22:08:59.940997Z","shell.execute_reply.started":"2024-07-02T22:07:18.791857Z","shell.execute_reply":"2024-07-02T22:08:59.939737Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import (\n    LoraConfig,\n    PeftModel,\n    prepare_model_for_kbit_training,\n    get_peft_model,\n)\nimport os, torch, wandb\nfrom datasets import load_dataset\nfrom trl import SFTTrainer, setup_chat_format","metadata":{"execution":{"iopub.status.busy":"2024-07-02T22:08:59.943040Z","iopub.execute_input":"2024-07-02T22:08:59.943360Z","iopub.status.idle":"2024-07-02T22:09:19.729395Z","shell.execute_reply.started":"2024-07-02T22:08:59.943330Z","shell.execute_reply":"2024-07-02T22:09:19.728548Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-07-02 22:09:07.269280: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-02 22:09:07.269413: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-02 22:09:07.409533: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nhf_token = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n\nlogin(token = hf_token)\n\nwb_token = user_secrets.get_secret(\"wandb\")\n\nwandb.login(key=wb_token)\nrun = wandb.init(\n    project='Fine-tune Llama 3 8B on Medical Dataset', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T22:11:04.918003Z","iopub.execute_input":"2024-07-02T22:11:04.919102Z","iopub.status.idle":"2024-07-02T22:11:25.010410Z","shell.execute_reply.started":"2024-07-02T22:11:04.919048Z","shell.execute_reply":"2024-07-02T22:11:25.009415Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtjiaz\u001b[0m (\u001b[33mtjiaz-Zedflux\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240702_221108-ugwbbp9q</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tjiaz-Zedflux/Fine-tune%20Llama%203%208B%20on%20Medical%20Dataset/runs/ugwbbp9q' target=\"_blank\">wobbly-dream-5</a></strong> to <a href='https://wandb.ai/tjiaz-Zedflux/Fine-tune%20Llama%203%208B%20on%20Medical%20Dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tjiaz-Zedflux/Fine-tune%20Llama%203%208B%20on%20Medical%20Dataset' target=\"_blank\">https://wandb.ai/tjiaz-Zedflux/Fine-tune%20Llama%203%208B%20on%20Medical%20Dataset</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tjiaz-Zedflux/Fine-tune%20Llama%203%208B%20on%20Medical%20Dataset/runs/ugwbbp9q' target=\"_blank\">https://wandb.ai/tjiaz-Zedflux/Fine-tune%20Llama%203%208B%20on%20Medical%20Dataset/runs/ugwbbp9q</a>"},"metadata":{}}]},{"cell_type":"code","source":"base_model = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\ndataset_name = \"ruslanmv/ai-medical-chatbot\"\nnew_model = \"llama-3-8b-chat-doctor\"","metadata":{"execution":{"iopub.status.busy":"2024-07-02T22:12:23.001942Z","iopub.execute_input":"2024-07-02T22:12:23.002730Z","iopub.status.idle":"2024-07-02T22:12:23.008068Z","shell.execute_reply.started":"2024-07-02T22:12:23.002693Z","shell.execute_reply":"2024-07-02T22:12:23.006917Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"torch_dtype = torch.float16\nattn_implementation = \"eager\"","metadata":{"execution":{"iopub.status.busy":"2024-07-02T22:12:35.937625Z","iopub.execute_input":"2024-07-02T22:12:35.938011Z","iopub.status.idle":"2024-07-02T22:12:35.943990Z","shell.execute_reply.started":"2024-07-02T22:12:35.937981Z","shell.execute_reply":"2024-07-02T22:12:35.942965Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# QLoRA config\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch_dtype,\n    bnb_4bit_use_double_quant=True,\n)\n\n# Load model\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    attn_implementation=attn_implementation\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T22:12:40.031800Z","iopub.execute_input":"2024-07-02T22:12:40.032720Z","iopub.status.idle":"2024-07-02T22:14:19.073245Z","shell.execute_reply.started":"2024-07-02T22:12:40.032680Z","shell.execute_reply":"2024-07-02T22:14:19.072181Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15a9fde995f84b7b9fd987f3aeef7592"}},"metadata":{}}]},{"cell_type":"code","source":"# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(base_model)\nmodel, tokenizer = setup_chat_format(model, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T22:15:53.500792Z","iopub.execute_input":"2024-07-02T22:15:53.501145Z","iopub.status.idle":"2024-07-02T22:15:54.038963Z","shell.execute_reply.started":"2024-07-02T22:15:53.501116Z","shell.execute_reply":"2024-07-02T22:15:54.037835Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"# LoRA config\npeft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n)\nmodel = get_peft_model(model, peft_config)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T22:16:31.633112Z","iopub.execute_input":"2024-07-02T22:16:31.633790Z","iopub.status.idle":"2024-07-02T22:16:32.428014Z","shell.execute_reply.started":"2024-07-02T22:16:31.633758Z","shell.execute_reply":"2024-07-02T22:16:32.427054Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#Importing the dataset\ndataset = load_dataset(dataset_name, split=\"all\")\ndataset = dataset.shuffle(seed=65).select(range(1000)) # Only use 1000 samples for quick demo\n\ndef format_chat_template(row):\n    row_json = [{\"role\": \"user\", \"content\": row[\"Patient\"]},\n               {\"role\": \"assistant\", \"content\": row[\"Doctor\"]}]\n    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n    return row\n\ndataset = dataset.map(\n    format_chat_template,\n    num_proc=4,\n)\n\ndataset['text'][3]","metadata":{"execution":{"iopub.status.busy":"2024-07-02T22:16:36.116889Z","iopub.execute_input":"2024-07-02T22:16:36.117270Z","iopub.status.idle":"2024-07-02T22:16:41.111726Z","shell.execute_reply.started":"2024-07-02T22:16:36.117239Z","shell.execute_reply":"2024-07-02T22:16:41.110705Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/863 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ded6a415433c4e42b0b3da3f11486743"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/142M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5882341184fd494d9beee7b9ea21254d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/256916 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65172303eda04351b8dfcdf465f70606"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a9cba10795340b7a0dca49710c9fe83"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'<|im_start|>user\\nFell on sidewalk face first about 8 hrs ago. Swollen, cut lip bruised and cut knee, and hurt pride initially. Now have muscle and shoulder pain, stiff jaw(think this is from the really swollen lip),pain in wrist, and headache. I assume this is all normal but are there specific things I should look for or will I just be in pain for a while given the hard fall?<|im_end|>\\n<|im_start|>assistant\\nHello and welcome to HCM,The injuries caused on various body parts have to be managed.The cut and swollen lip has to be managed by sterile dressing.The body pains, pain on injured site and jaw pain should be managed by pain killer and muscle relaxant.I suggest you to consult your primary healthcare provider for clinical assessment.In case there is evidence of infection in any of the injured sites, a course of antibiotics may have to be started to control the infection.Thanks and take careDr Shailja P Wahal<|im_end|>\\n'"},"metadata":{}}]},{"cell_type":"code","source":"dataset = dataset.train_test_split(test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T22:16:50.719129Z","iopub.execute_input":"2024-07-02T22:16:50.719511Z","iopub.status.idle":"2024-07-02T22:16:50.736529Z","shell.execute_reply.started":"2024-07-02T22:16:50.719477Z","shell.execute_reply":"2024-07-02T22:16:50.735743Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"training_arguments = TrainingArguments(\n    output_dir=new_model,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=2,\n    optim=\"paged_adamw_32bit\",\n    num_train_epochs=1,\n    evaluation_strategy=\"steps\",\n    eval_steps=0.2,\n    logging_steps=1,\n    warmup_steps=10,\n    logging_strategy=\"steps\",\n    learning_rate=2e-4,\n    fp16=False,\n    bf16=False,\n    group_by_length=True,\n    report_to=\"wandb\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T22:16:55.568778Z","iopub.execute_input":"2024-07-02T22:16:55.569132Z","iopub.status.idle":"2024-07-02T22:16:55.602150Z","shell.execute_reply.started":"2024-07-02T22:16:55.569105Z","shell.execute_reply":"2024-07-02T22:16:55.601296Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    peft_config=peft_config,\n    max_seq_length=512,\n    dataset_text_field=\"text\",\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing= False,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T22:17:14.243389Z","iopub.execute_input":"2024-07-02T22:17:14.244010Z","iopub.status.idle":"2024-07-02T22:17:15.560250Z","shell.execute_reply.started":"2024-07-02T22:17:14.243978Z","shell.execute_reply":"2024-07-02T22:17:15.555919Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '1.0.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1961: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:269: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:307: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/900 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95a78f3a08df4be69f29b91f055fe473"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20bb4a08a5a04ba1856e2adc41f1e552"}},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-07-02T23:03:32.954919Z","iopub.execute_input":"2024-07-02T23:03:32.955612Z","iopub.status.idle":"2024-07-02T23:33:13.553834Z","shell.execute_reply.started":"2024-07-02T23:03:32.955582Z","shell.execute_reply":"2024-07-02T23:33:13.552987Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='450' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [450/450 29:33, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>90</td>\n      <td>1.842300</td>\n      <td>2.601689</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>2.239300</td>\n      <td>2.557078</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>1.856700</td>\n      <td>2.561585</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>1.666500</td>\n      <td>2.530420</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.186300</td>\n      <td>2.518548</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=450, training_loss=1.7588663569423888, metrics={'train_runtime': 1779.5301, 'train_samples_per_second': 0.506, 'train_steps_per_second': 0.253, 'total_flos': 9250054858014720.0, 'train_loss': 1.7588663569423888, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"wandb.finish()\nmodel.config.use_cache = True","metadata":{"execution":{"iopub.status.busy":"2024-07-02T23:33:21.704491Z","iopub.execute_input":"2024-07-02T23:33:21.705055Z","iopub.status.idle":"2024-07-02T23:33:25.788626Z","shell.execute_reply.started":"2024-07-02T23:33:21.705020Z","shell.execute_reply":"2024-07-02T23:33:25.787941Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.037 MB of 0.037 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▇▅▃▂▃▂▁█▆▆▅▄</td></tr><tr><td>eval/runtime</td><td>▁▂▃▁█▆▇█▅█▅▂</td></tr><tr><td>eval/samples_per_second</td><td>████▁██▁█▁██</td></tr><tr><td>eval/steps_per_second</td><td>████▁██▁█▁██</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇▁▂▂▃▃▄▄▄▅▅▆▁▂▂▃▃▄▄▅▅▅▆▆▇▇█</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇▁▂▂▃▃▄▄▄▅▅▆▁▂▂▃▃▄▄▅▅▅▆▆▇▇█</td></tr><tr><td>train/grad_norm</td><td>▂▃▂▃▂▁▄▁▂▂▁▂▁▂▂▃▄▂▄▃▃▂▁▄▂▅▅▅▄▇▄▄▅▄▆▅▃▄▄█</td></tr><tr><td>train/learning_rate</td><td>██▇▇▆▆▅▅▄▄▃▃▂▂█▇▇▆▆▅▅▅▄▄▂█▇▇▆▆▅▅▄▄▄▃▃▂▂▁</td></tr><tr><td>train/loss</td><td>▇█▇▇▆▆▆▆▆▆▇▅▆▄▅▄▆▅▃▆▅▂▅▄▅▁▅▄▂▄▂▄▄▅▅▇▄▂▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.51855</td></tr><tr><td>eval/runtime</td><td>76.2217</td></tr><tr><td>eval/samples_per_second</td><td>1.312</td></tr><tr><td>eval/steps_per_second</td><td>1.312</td></tr><tr><td>total_flos</td><td>9250054858014720.0</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>450</td></tr><tr><td>train/grad_norm</td><td>4.05598</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.1863</td></tr><tr><td>train_loss</td><td>1.75887</td></tr><tr><td>train_runtime</td><td>1779.5301</td></tr><tr><td>train_samples_per_second</td><td>0.506</td></tr><tr><td>train_steps_per_second</td><td>0.253</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">wobbly-dream-5</strong> at: <a href='https://wandb.ai/tjiaz-Zedflux/Fine-tune%20Llama%203%208B%20on%20Medical%20Dataset/runs/ugwbbp9q' target=\"_blank\">https://wandb.ai/tjiaz-Zedflux/Fine-tune%20Llama%203%208B%20on%20Medical%20Dataset/runs/ugwbbp9q</a><br/> View project at: <a href='https://wandb.ai/tjiaz-Zedflux/Fine-tune%20Llama%203%208B%20on%20Medical%20Dataset' target=\"_blank\">https://wandb.ai/tjiaz-Zedflux/Fine-tune%20Llama%203%208B%20on%20Medical%20Dataset</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240702_221108-ugwbbp9q/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."},"metadata":{}}]},{"cell_type":"code","source":"messages = [\n    {\n        \"role\": \"user\",\n        \"content\": \"Hello doctor, I have bad acne. How do I get rid of it?\"\n    }\n]\n\nprompt = tokenizer.apply_chat_template(messages, tokenize=False, \n                                       add_generation_prompt=True)\n\ninputs = tokenizer(prompt, return_tensors='pt', padding=True, \n                   truncation=True).to(\"cuda\")\n\noutputs = model.generate(**inputs, max_length=150, \n                         num_return_sequences=1)\n\ntext = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprint(text.split(\"assistant\")[1])","metadata":{"execution":{"iopub.status.busy":"2024-07-02T23:33:35.169981Z","iopub.execute_input":"2024-07-02T23:33:35.170323Z","iopub.status.idle":"2024-07-02T23:33:52.028304Z","shell.execute_reply.started":"2024-07-02T23:33:35.170297Z","shell.execute_reply":"2024-07-02T23:33:52.027381Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"name":"stdout","text":"\nHi. I have gone through your query. I can understand your concern. Acne is a very common problem and it can be controlled. You can use a topical antibiotic cream like metronidazole gel at night. You can also use a retinoid cream like Adapalene plus Clindamycin in the morning. You can use a sunscreen with spf 30 or more during the day. You can also take a tablet like Doxycycline once daily at night. You can take this medicine for three to four weeks. You can also use a face wash like Benzoyl peroxide face wash\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.model.save_pretrained(new_model)\n# trainer.model.push_to_hub(new_model, use_temp_dir=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T23:59:53.494748Z","iopub.execute_input":"2024-07-02T23:59:53.495802Z","iopub.status.idle":"2024-07-02T23:59:53.917714Z","shell.execute_reply.started":"2024-07-02T23:59:53.495757Z","shell.execute_reply":"2024-07-02T23:59:53.916720Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"trainer.model.push_to_hub(new_model, use_temp_dir=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T00:00:23.521101Z","iopub.execute_input":"2024-07-03T00:00:23.521983Z","iopub.status.idle":"2024-07-03T00:00:23.910355Z","shell.execute_reply.started":"2024-07-03T00:00:23.521946Z","shell.execute_reply":"2024-07-03T00:00:23.908977Z"},"trusted":true},"execution_count":25,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n","\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://huggingface.co/api/repos/create","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_temp_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:914\u001b[0m, in \u001b[0;36mPushToHubMixin.push_to_hub\u001b[0;34m(self, repo_id, use_temp_dir, commit_message, private, token, max_shard_size, create_pr, safe_serialization, revision, commit_description, tags, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    911\u001b[0m repo_url \u001b[38;5;241m=\u001b[39m deprecated_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    912\u001b[0m organization \u001b[38;5;241m=\u001b[39m deprecated_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morganization\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 914\u001b[0m repo_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_repo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprivate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morganization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morganization\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;66;03m# Create a new empty model card and eventually tag it\u001b[39;00m\n\u001b[1;32m    919\u001b[0m model_card \u001b[38;5;241m=\u001b[39m create_and_tag_model_card(\n\u001b[1;32m    920\u001b[0m     repo_id, tags, token\u001b[38;5;241m=\u001b[39mtoken, ignore_metadata_errors\u001b[38;5;241m=\u001b[39mignore_metadata_errors\n\u001b[1;32m    921\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:730\u001b[0m, in \u001b[0;36mPushToHubMixin._create_repo\u001b[0;34m(self, repo_id, private, token, repo_url, organization)\u001b[0m\n\u001b[1;32m    727\u001b[0m             repo_id \u001b[38;5;241m=\u001b[39m repo_id\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    728\u001b[0m         repo_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morganization\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 730\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprivate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m url\u001b[38;5;241m.\u001b[39mrepo_id\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/hf_api.py:3269\u001b[0m, in \u001b[0;36mHfApi.create_repo\u001b[0;34m(self, repo_id, token, private, repo_type, exist_ok, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[1;32m   3267\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m RepoUrl(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3268\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m HfHubHTTPError:\n\u001b[0;32m-> 3269\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m   3270\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/hf_api.py:3256\u001b[0m, in \u001b[0;36mHfApi.create_repo\u001b[0;34m(self, repo_id, token, private, repo_type, exist_ok, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[1;32m   3253\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   3255\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3256\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3257\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   3258\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exist_ok \u001b[38;5;129;01mand\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m409\u001b[39m:\n\u001b[1;32m   3259\u001b[0m         \u001b[38;5;66;03m# Repo already exists and `exist_ok=True`\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:367\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[1;32m    361\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Forbidden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCannot access content at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf you are trying to create or update content,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmake sure you have a token with the `write` role.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HfHubHTTPError(message, response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HfHubHTTPError(\u001b[38;5;28mstr\u001b[39m(e), response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n","\u001b[0;31mHfHubHTTPError\u001b[0m:  (Request ID: Root=1-66849497-699f846e268fcdf56be73100;c089db5e-11ff-4bdb-9643-b9e771a55391)\n\n403 Forbidden: You don't have the rights to create a model under the namespace \"tjiaz\".\nCannot access content at: https://huggingface.co/api/repos/create.\nIf you are trying to create or update content,make sure you have a token with the `write` role."],"ename":"HfHubHTTPError","evalue":" (Request ID: Root=1-66849497-699f846e268fcdf56be73100;c089db5e-11ff-4bdb-9643-b9e771a55391)\n\n403 Forbidden: You don't have the rights to create a model under the namespace \"tjiaz\".\nCannot access content at: https://huggingface.co/api/repos/create.\nIf you are trying to create or update content,make sure you have a token with the `write` role.","output_type":"error"}]}]}